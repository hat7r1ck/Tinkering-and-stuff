import os
import yaml
import pandas as pd
from datetime import datetime

def load_yml_files(folder_path, skip_deprecated=True):
    """
    Recursively loads .yml/.yaml files from folder_path.
    Skips subfolders with 'deprecated' if skip_deprecated=True.
    """
    all_data = []
    for root, dirs, files in os.walk(folder_path):
        if skip_deprecated and 'deprecated' in root.lower():
            continue
        for file_name in files:
            if file_name.endswith(('.yml', '.yaml')):
                file_path = os.path.join(root, file_name)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = yaml.safe_load(f)
                        if content:
                            all_data.append(content)
                except Exception as e:
                    print(f"Error loading {file_path}: {e}")
    return all_data

def safe_parse_date(date_string):
    """Parse date as YYYY-MM-DD, else return 'Unknown Date'."""
    if not date_string:
        return "Unknown Date"
    try:
        return datetime.strptime(date_string, "%Y-%m-%d").strftime("%Y-%m-%d")
    except ValueError:
        return "Unknown Date"

# Update these paths as needed:
detections_folder = r"/path/to/detections"
stories_folder    = r"/path/to/stories"
mitre_csv_path    = r"/path/to/mitre_exploded.csv"  # Note: use exploded CSV here
output_csv_path   = r"/path/to/final_merged_output.csv"

# 1) Load YAML files + MITRE CSV
detections_yml = load_yml_files(detections_folder, skip_deprecated=True)
stories_yml    = load_yml_files(stories_folder, skip_deprecated=False)
mitre_df       = pd.read_csv(mitre_csv_path)

# 2) Process Detections
detection_rows = []
for det in detections_yml:
    # Optionally skip detection if status=='deprecated'
    if det.get("status", "").lower() == "deprecated":
        continue

    d_name   = det.get("name", "Unknown Detection")
    d_id     = det.get("id", "")
    d_ver    = det.get("version", "")
    d_date   = safe_parse_date(det.get("date"))
    d_author = det.get("author", "")
    d_stat   = det.get("status", "")
    d_type   = det.get("type", "")
    d_desc   = det.get("description", "")
    d_search = det.get("search", "")
    d_impl   = det.get("how_to_implement", "")
    d_fp     = det.get("known_false_positives", "")

    ds_list  = det.get("data_source", [])
    if not isinstance(ds_list, list):
        ds_list = [ds_list]
    ds_joined = "|".join(ds_list)

    tags  = det.get("tags", {})
    # If your detections have "tactics" or "mitre_attack_tactics"
    # adjust as necessary. This example uses "tactics".
    tacts = tags.get("tactics", [])
    if not isinstance(tacts, list):
        tacts = [tacts]
    tacts_joined = "|".join(tacts)

    # If detection references multiple MITRE IDs, we store them in "mitre_id".
    # But now that your MITRE CSV is exploded, each ID in that CSV is just 1 row.
    # We'll still create multiple rows if your YAML has multiple mitre_attack_ids.
    m_ids = tags.get("mitre_attack_id", [])
    if not isinstance(m_ids, list):
        m_ids = [m_ids] if m_ids else []

    if not m_ids:
        detection_rows.append({
            "detection_name": d_name,
            "detection_id": d_id,
            "detection_version": d_ver,
            "detection_date": d_date,
            "detection_author": d_author,
            "detection_status": d_stat,
            "detection_type": d_type,
            "detection_description": d_desc,
            "detection_search": d_search,
            "detection_how_to_implement": d_impl,
            "detection_known_false_positives": d_fp,
            "data_sources": ds_joined,
            "tactics": tacts_joined,
            "mitre_id": None
        })
    else:
        for mid in m_ids:
            detection_rows.append({
                "detection_name": d_name,
                "detection_id": d_id,
                "detection_version": d_ver,
                "detection_date": d_date,
                "detection_author": d_author,
                "detection_status": d_stat,
                "detection_type": d_type,
                "detection_description": d_desc,
                "detection_search": d_search,
                "detection_how_to_implement": d_impl,
                "detection_known_false_positives": d_fp,
                "data_sources": ds_joined,
                "tactics": tacts_joined,
                "mitre_id": mid
            })

detections_df = pd.DataFrame(detection_rows)

# 3) Process Stories
story_rows = []
for s in stories_yml:
    s_name  = s.get("name", "Unknown Story")
    s_id    = s.get("id", "")
    s_ver   = s.get("version", "")
    s_date  = safe_parse_date(s.get("date"))
    s_auth  = s.get("author", "")
    s_desc  = s.get("description", "")
    s_narr  = s.get("narrative", "")

    p_list = s.get("products", [])
    if not isinstance(p_list, list):
        p_list = [p_list]
    products_joined = "|".join(p_list)

    d_list = s.get("detections", [])
    if not isinstance(d_list, list):
        d_list = [d_list]

    if not d_list:
        story_rows.append({
            "story_name": s_name, "story_id": s_id,
            "story_version": s_ver, "story_date": s_date,
            "story_author": s_auth, "story_description": s_desc,
            "story_narrative": s_narr, "products": products_joined,
            "detection_name": None
        })
    else:
        for d_n in d_list:
            story_rows.append({
                "story_name": s_name, "story_id": s_id,
                "story_version": s_ver, "story_date": s_date,
                "story_author": s_auth, "story_description": s_desc,
                "story_narrative": s_narr, "products": products_joined,
                "detection_name": d_n
            })

stories_df = pd.DataFrame(story_rows)

# 4) Merge stories + detections on detection_name
story_det_df = pd.merge(stories_df, detections_df, how="left", on="detection_name")

# 5) Merge with exploded MITRE CSV on "mitre_id"
final_df = pd.merge(story_det_df, mitre_df, how="left", on="mitre_id")

# 6) Reorder columns as desired
columns_order = [
    "story_name","story_id","story_version","story_date","story_author",
    "products","story_description","story_narrative",
    "detection_name","detection_id","detection_version","detection_date",
    "detection_author","detection_status","detection_type","data_sources","tactics",
    "detection_description","detection_search","detection_how_to_implement",
    "detection_known_false_positives",
    "mitre_id","technique","mitre_tactic","mitre_group"
]
existing_cols = [c for c in columns_order if c in final_df.columns]
final_df = final_df[existing_cols]

# 7) Save final CSV
final_df.to_csv(output_csv_path, index=False, encoding='utf-8')
print(f"Final merged CSV: {output_csv_path}")
