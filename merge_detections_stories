import os
import yaml
import pandas as pd
from datetime import datetime

def load_yml_files(folder_path, skip_deprecated=True):
    all_data = []
    for root, dirs, files in os.walk(folder_path):
        if skip_deprecated and 'deprecated' in root.lower():
            continue
        for file_name in files:
            if file_name.endswith(('.yml', '.yaml')):
                file_path = os.path.join(root, file_name)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = yaml.safe_load(f)
                        if content:
                            all_data.append(content)
                except Exception as e:
                    print(f"Error loading {file_path}: {e}")
    return all_data

def safe_parse_date(date_string):
    if not date_string:
        return "Unknown Date"
    try:
        return datetime.strptime(date_string, "%Y-%m-%d").strftime("%Y-%m-%d")
    except ValueError:
        return "Unknown Date"

# --------------------- EDIT THESE PATHS ---------------------
detections_folder = r"/path/to/detections"
stories_folder    = r"/path/to/stories"
mitre_csv_path    = r"/path/to/mitre_exploded.csv"
output_csv_path   = r"/path/to/final_merged_exploded.csv"
# -----------------------------------------------------------

# 1) Load files
detections_yml = load_yml_files(detections_folder, skip_deprecated=True)
stories_yml    = load_yml_files(stories_folder, skip_deprecated=False)
mitre_df       = pd.read_csv(mitre_csv_path)

# 2) Process detections (explode multiple MITRE IDs)
detection_rows = []
for det in detections_yml:
    if det.get("status", "").lower() == "deprecated":
        continue

    d_name   = det.get("name", "Unknown Detection")
    d_id     = det.get("id", "")
    d_ver    = det.get("version", "")
    d_date   = safe_parse_date(det.get("date"))
    d_author = det.get("author", "")
    d_stat   = det.get("status", "")
    d_type   = det.get("type", "")
    d_desc   = det.get("description", "")
    d_search = det.get("search", "")
    d_impl   = det.get("how_to_implement", "")
    d_fp     = det.get("known_false_positives", "")

    data_source_list = det.get("data_source", [])
    if not isinstance(data_source_list, list):
        data_source_list = [data_source_list]
    data_sources_joined = "|".join(data_source_list)

    tags = det.get("tags", {})
    tacts = tags.get("tactics", [])
    if not isinstance(tacts, list):
        tacts = [tacts]
    tacts_joined = "|".join(tacts)

    # Detection-level products
    det_prod_list = tags.get("product", [])
    if not isinstance(det_prod_list, list):
        det_prod_list = [det_prod_list]
    detection_products_joined = "|".join(det_prod_list)

    # Possibly multiple MITRE IDs
    m_ids = tags.get("mitre_attack_id", [])
    if not isinstance(m_ids, list):
        m_ids = [m_ids] if m_ids else []

    if not m_ids:
        detection_rows.append({
            "detection_name": d_name,
            "detection_id": d_id,
            "detection_version": d_ver,
            "detection_date": d_date,
            "detection_author": d_author,
            "detection_status": d_stat,
            "detection_type": d_type,
            "detection_description": d_desc,
            "detection_search": d_search,
            "detection_how_to_implement": d_impl,
            "detection_known_false_positives": d_fp,
            "data_sources": data_sources_joined,
            "tactics": tacts_joined,
            "detection_products": detection_products_joined,
            "mitre_id": None
        })
    else:
        for mid in m_ids:
            detection_rows.append({
                "detection_name": d_name,
                "detection_id": d_id,
                "detection_version": d_ver,
                "detection_date": d_date,
                "detection_author": d_author,
                "detection_status": d_stat,
                "detection_type": d_type,
                "detection_description": d_desc,
                "detection_search": d_search,
                "detection_how_to_implement": d_impl,
                "detection_known_false_positives": d_fp,
                "data_sources": data_sources_joined,
                "tactics": tacts_joined,
                "detection_products": detection_products_joined,
                "mitre_id": mid
            })

detections_df = pd.DataFrame(detection_rows)

# 3) Process stories
story_rows = []
for s in stories_yml:
    s_name = s.get("name", "Unknown Story")
    s_id   = s.get("id", "")
    s_ver  = s.get("version", "")
    s_date = safe_parse_date(s.get("date"))
    s_auth = s.get("author", "")
    s_desc = s.get("description", "")
    s_narr = s.get("narrative", "")

    # Story-level products
    story_prod_list = s.get("products", [])
    if not isinstance(story_prod_list, list):
        story_prod_list = [story_prod_list]
    story_products_joined = "|".join(story_prod_list)

    det_list = s.get("detections", [])
    if not isinstance(det_list, list):
        det_list = [det_list]

    if not det_list:
        # No detections -> produce a single row
        story_rows.append({
            "story_name": s_name,
            "story_id": s_id,
            "story_version": s_ver,
            "story_date": s_date,
            "story_author": s_auth,
            "story_description": s_desc,
            "story_narrative": s_narr,
            "products": story_products_joined,
            "detection_name": None
        })
    else:
        for d_n in det_list:
            story_rows.append({
                "story_name": s_name,
                "story_id": s_id,
                "story_version": s_ver,
                "story_date": s_date,
                "story_author": s_auth,
                "story_description": s_desc,
                "story_narrative": s_narr,
                "products": story_products_joined,
                "detection_name": d_n
            })

stories_df = pd.DataFrame(story_rows)

# 4) Merge stories + detections on detection_name
story_det_df = pd.merge(stories_df, detections_df, how="left", on="detection_name")

# 5) Merge with exploded MITRE CSV
merged_df = pd.merge(story_det_df, mitre_df, how="left", on="mitre_id")

# 6) Combine + Explode Products Without Duplicates
#    We'll gather story products + detection products, merge them into a set,
#    then explode so each row has exactly one product.

def combine_and_explode_products(row):
    s_products = row["products"].split("|") if pd.notnull(row["products"]) else []
    d_products = row["detection_products"].split("|") if pd.notnull(row["detection_products"]) else []
    # Merge them in a set to remove duplicates
    combined = set(s_products + d_products) - {""}  # remove empty
    return list(combined)  # Convert back to list for explode

merged_df["combined_products"] = merged_df.apply(combine_and_explode_products, axis=1)

# Explode => one row per product
final_df = merged_df.explode("combined_products", ignore_index=True)

# Rename
final_df.rename(columns={"combined_products": "product"}, inplace=True)

# 7) Reorder columns, removing old pipe-delimited product columns if desired
columns_order = [
    "story_name","story_id","story_version","story_date","story_author",
    "story_description","story_narrative",
    # If you want to keep them:
    "products",          # story-level pipe-delimited
    "detection_products",# detection-level pipe-delimited
    "product",           # final exploded product (deduped)
    "detection_name","detection_id","detection_version","detection_date",
    "detection_author","detection_status","detection_type","data_sources",
    "tactics","detection_description","detection_search","detection_how_to_implement",
    "detection_known_false_positives",
    "mitre_id","technique","mitre_tactic","mitre_group"
]

existing_cols = [c for c in columns_order if c in final_df.columns]
final_df = final_df[existing_cols]

# 8) Save
final_df.to_csv(output_csv_path, index=False, encoding='utf-8')
print(f"Final exploded CSV saved: {output_csv_path}")
